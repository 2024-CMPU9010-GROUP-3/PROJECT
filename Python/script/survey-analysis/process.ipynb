{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data from the Market Research Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# import csv file as dataframe\n",
    "data_path = \"tudublin_amenities_access_survey.csv\"\n",
    "survey_data = pd.read_csv(data_path, delimiter=\",\", encoding='unicode_escape')\n",
    "survey_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of rows and columns\n",
    "print(\"Number of columns: \", len(survey_data.columns))\n",
    "print(\"Number of rows: \", len(survey_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type of columns -- all object\n",
    "print(\"Data types of columns:\")\n",
    "survey_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First order of business: clean up the df\n",
    "<li> I will start by removing the unecessary columns: start & completion time, name & email because they're empty.<br></li>\n",
    "<li>Need to rename the columns as well</li>\n",
    "<li>Next, I will fill in the NAN in county responses, and group the different \"other\" responses in job<br></li>\n",
    "<li>Then, I will split the df into those who are employed and unemployed, and then those who use public amenities or not in their professional life.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unecessary columns\n",
    "survey_data = survey_data.drop(survey_data.columns[[1,2,3,4]], axis=1)\n",
    "\n",
    "# import column names\n",
    "col_file = open(\"col_names.txt\", \"r\")\n",
    "col_names = col_file.read()\n",
    "col_list = col_names.replace(' ','').split(\",\")\n",
    "col_file.close()\n",
    "\n",
    "# rename columns\n",
    "survey_data = survey_data.set_axis(col_list, axis=1)\n",
    "print(survey_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trailing semicolons in all columns\n",
    "survey_data = survey_data.map(lambda x: x.rstrip(';') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the \"other\" answers together in new/existing categories using dictionaries and mapping\n",
    "sector_list_replace = [\"Education\",\"Government\", \"Construction\", \"Hospitality\", \"Technology\", \"Other\"]\n",
    "\n",
    "sector_dict = {\n",
    "    sector_list_replace[0] : [\"Student\"],\n",
    "    sector_list_replace[1] : [\"Local Government\",\"COUNTY COUNCIL\"],\n",
    "    sector_list_replace[2] : [\"Architecture\"],\n",
    "    sector_list_replace[3] : [\"Services (events)\",\"Food\",\"Fast food\",\"Food Service\",\"restaurant\"],\n",
    "    sector_list_replace[4] : [\"IT\",\"Software Development\",\"Technology/Finance\",\"Data\",\"IT solutions and services.\",\"Cybersecurity \",\"Tech\"],\n",
    "    sector_list_replace[5] : [\"Pharmaceuticals\",\"Arts\",\"Mechanic\"]\n",
    "}\n",
    "\n",
    "sector_map = {item: sector for sector, items in sector_dict.items() for item in items}\n",
    "survey_data[\"sector\"] = survey_data[\"sector\"].map(sector_map).fillna(survey_data[\"sector\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>I combined food services, restaurant, fast food and service events under hospitality\n",
    "<li>I combined the different versions of tech, cybersecurity, IT under techonology\n",
    "<li>I put architecture under construction\n",
    "<li>I put student under education\n",
    "<li>Any other sector which constituted 1 response, I put it under Other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in 2 sub dataframe, those that use amenity data for work and those who dont\n",
    "# user A = dont' use amenity data\n",
    "# user B = use amenity data\n",
    "\n",
    "users_A = pd.DataFrame(survey_data[survey_data[\"use_amenity_data\"] == \"No\"])\n",
    "users_B = pd.DataFrame(survey_data[survey_data[\"use_amenity_data\"] == \"Yes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre process user_A = Those that DONT USE amenity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless columns aka those with only NAN values\n",
    "users_A = users_A.dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "# replace NaN with \"unapplicable\" in columns users did not answer (branching) and \"empty\" with those users chose to not answer\n",
    "## made a mistake in the branching for this section, other_amenity sends to contact, demo sends to other feature instead of other amenity as well\n",
    "\n",
    "A_branch_cols_list = users_A.columns[7:9].tolist()\n",
    "A_unrequired_cols_list = users_A.columns[9:].tolist()\n",
    "\n",
    "def solve_nan(df, col_list, value):\n",
    "    for col in col_list:\n",
    "        df[col] = df[col].fillna(value)\n",
    "\n",
    "solve_nan(users_A, A_branch_cols_list, \"Unapplicable\")\n",
    "solve_nan(users_A, A_unrequired_cols_list, \"Empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle \"other\" answers\n",
    "def prefix_other_answers(row, answer):\n",
    "    items = row.split(\";\") # split\n",
    "    updated_items = [\n",
    "        item if item.strip() in answer else f\"Other: {item.strip()}\"\n",
    "        for item in items\n",
    "    ]\n",
    "    return \"; \".join(updated_items)  # join back\n",
    "\n",
    "# adding \"other\" prefix to why impractical demo personal answers\n",
    "neg_reason_demo_list = [\"Already have access to this information\",\"I don't like web applications\",\"Empty\",\"Unapplicable\"]\n",
    "users_A[\"why_impractical_demo_personal\"] = users_A[\"why_impractical_demo_personal\"].apply(prefix_other_answers, answer=neg_reason_demo_list)\n",
    "\n",
    "# adding \"other\" prefix to additional amenity \"other\" answers\n",
    "other_amenity_list = [\"Bike lanes\",\"Bike sheds\",\"Hiking trails\",\"Car parking\",\"Parks\",\"Public bathrooms\",\"Empty\",\"Unapplicable\"]\n",
    "users_B[\"other_amenity_work\"] = users_B[\"other_amenity_work\"].apply(prefix_other_answers, answer=other_amenity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_A.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode multiple answers cols \n",
    "\n",
    "def explode_multiple_answers(data, column_names, delimiter=';'):\n",
    "    \"\"\"\n",
    "    Function to plot the count of devices in a specified column, handling multiple answers.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame containing the survey data\n",
    "    - column_name: The name of the column to analyze (e.g., 'device_personal')\n",
    "    - delimiter: The delimiter separating multiple values (default is ';')\n",
    "    \n",
    "    Returns:\n",
    "    - A Plotly bar chart\n",
    "    \"\"\"\n",
    "    # Loop through the list of columns and apply the split and explode process\n",
    "    for column_name in column_names:\n",
    "        if column_name in data.columns:\n",
    "            # Check if the delimiter exists in any of the rows of the column\n",
    "            if data[column_name].str.contains(delimiter).any():\n",
    "                # Split the values in the column by the delimiter\n",
    "                data[column_name + '_exploded'] = data[column_name].str.split(delimiter)\n",
    "                # Explode the column to create multiple rows\n",
    "                data = data.explode(column_name + '_exploded')\n",
    "            else:\n",
    "                # If no delimiter is found, no need to split or explode\n",
    "                data[column_name + '_exploded'] = data[column_name]  # Keep original values in a new column\n",
    "    \n",
    "    return data\n",
    "\n",
    "userAcols_to_explode = [\"device_personal\",\"why_impractical_demo_personal\",\"other_amenity_personal\",\"other_feature_personal\"]\n",
    "\n",
    "users_A_expl = explode_multiple_answers(users_A,userAcols_to_explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_A_expl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export new csv user_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_A_expl.to_csv(\"userA_responses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user_B = Those that USE amenity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NAN in first row county with Mayo (Damian)\n",
    "users_B[\"county\"] = users_B[\"county\"].fillna(\"Mayo\")\n",
    "\n",
    "# remove useless columns aka those with only NAN values\n",
    "users_B = users_B.dropna(axis=1, how='all')\n",
    "\n",
    "# replace NaN with \"unapplicable\" in columns users did not answer (branching) and \"empty\" with those users chose to not answer\n",
    "\n",
    "branch_cols_list = [\"why_unsatisfied_tool_work\", \"why_impractical_demo_work\"]\n",
    "unrequired_cols_list = users_B.columns[[11]].tolist() + users_B.columns[15:].tolist()\n",
    "\n",
    "def solve_nan(df, col_list, value):\n",
    "    for col in col_list:\n",
    "        df[col] = df[col].fillna(value)\n",
    "\n",
    "solve_nan(users_B, branch_cols_list, \"Unapplicable\")\n",
    "solve_nan(users_B, unrequired_cols_list, \"Empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten answers for type amenity and type tool\n",
    "new_amenity_list = [\"Recreational\",\"Transport & Mobility\",\"Healthcare & Safety\", \"Technological\",\"Mechanical\",\"Accessibility\"]\n",
    "og_amenity_list = [\"Recreational (parks, sport facilities, hiking trails, public beaches, etc)\",\n",
    "                   \"Transport & mobility (bus stops, EV charging stations, parking, bicycle lanes, etc)\",\n",
    "                   \"Healthcare & Safety (emergency services, hospitals, pharmacies, public defibrillators, etc)\",\n",
    "                   \"Technological (public wi-fi, etc)\",\n",
    "                   \"Mechanical (water grid, electric grid, etc)\",\n",
    "                   \"Accessibility features (wheelchair ramps, tactile pavement, public toilets, etc)\"]\n",
    "\n",
    "new_tool_list = [\"Government database\",\"City software\",\"Navigation app\"]\n",
    "og_tool_list = [\"Government database (i.e: data.gov.ie)\",\n",
    "                   \"City planning or Zoning software\",\n",
    "                   \"Navigation applications (i.e: Google Maps)\"]\n",
    "\n",
    "# use mapping dict to account for multiple answers\n",
    "amenity_mapping = dict(zip(og_amenity_list, new_amenity_list))\n",
    "users_B[\"type_amenity_data_work\"] = users_B[\"type_amenity_data_work\"].apply(\n",
    "    lambda x: \";\".join([amenity_mapping.get(item.strip(), item.strip()) for item in x.split(\";\")])\n",
    ")\n",
    "tool_mapping = dict(zip(og_tool_list, new_tool_list))\n",
    "users_B[\"type_tool_work\"] = users_B[\"type_tool_work\"].apply(\n",
    "    lambda x: \";\".join([tool_mapping.get(item.strip(), item.strip()) for item in x.split(\";\")])\n",
    ")\n",
    "\n",
    "# adding \"other\" prefix to custom amenity answers\n",
    "users_B[\"type_amenity_data_work\"] = users_B[\"type_amenity_data_work\"].apply(prefix_other_answers, answer=new_amenity_list)\n",
    "\n",
    "# adding \"other\" prefix to custom tool answers\n",
    "users_B[\"type_tool_work\"] = users_B[\"type_tool_work\"].apply(prefix_other_answers, answer=new_tool_list)\n",
    "\n",
    "# adding \"other\" prefix to why satisfaction tool work \"other\" answers\n",
    "neg_reason_tool_list = [\"Incomplete information\",\"Not user friendly\",\"Slow - not modern\", \"Empty\",\"Unapplicable\"]\n",
    "users_B[\"why_unsatisfied_tool_work\"] = users_B[\"why_unsatisfied_tool_work\"].apply(prefix_other_answers, answer=neg_reason_tool_list)\n",
    "\n",
    "# adding \"other\" prefix to additional amenity \"other\" answers\n",
    "users_B[\"other_amenity_work\"] = users_B[\"other_amenity_work\"].apply(prefix_other_answers, answer=other_amenity_list)\n",
    "\n",
    "# adding \"other\" prefix to why impractical demo \"other\" answers\n",
    "users_B[\"why_impractical_demo_work\"] = users_B[\"why_impractical_demo_work\"].apply(prefix_other_answers, answer=neg_reason_demo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_B.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode mutiple answers cols\n",
    "userBcols_to_explode = [\"device_work\",\"type_amenity_data_work\",\"type_tool_work\",\"satisfaction_tool_work\",\"why_impractical_demo_work\",\"other_amenity_work\"]\n",
    "\n",
    "users_B_expl = explode_multiple_answers(users_B,userBcols_to_explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_B_expl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to csv user_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_B_expl.to_csv(\"userB_responses.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
