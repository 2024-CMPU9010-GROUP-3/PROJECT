\subsubsection{Backend Technologies}
\paragraph{Go}
At the start of the project, a portion of the team deliberated about which
technologies to choose for the backend. Options using JavaScript such as NodeJS
or Deno with accompanying frameworks like ExpressJS or NestJS were considered,
as was Rust and its Rocket framework. They would have been excellent choices as
they are well established in the industry and tried-and-tested.

The majority of the team has development experience with JavaScript, so going
with that would have made a lot of sense. However, it was planned from the very
beginning to deploy this application on a server hosted by one of the team
members. Therefore, the usage of computing and memory resources was very
important to them, as they did not want to strain their Kubernetes cluster more
than necessary. Since NodeJS runs on the JavaScript runtime V8, which also
powers Google Chrome, our experience indicated that it would be quite resource
intensive to run.

Due to this, the team shifted towards using compiled rather than interpreted
languages, as these are generally more resource efficient. Since small
executables and low memory usage was desired, languages and frameworks that run
on virtual machines such as Java with Spring or C\# with .Net were not deemed to
be viable options. As a result, only Rust and Go were seriously considered at
this point.

Rust offers a small package size, strong memory safety, an excellent
ecosystem and build-tools. The team member that would focus on backend
development had recent experience in writing Rust code. However, Rust
development can be very tricky and time consuming. Additionally, in our
experience Rust has above average compilation times. In a project with a fixed
deadline and the expectation of rapid development, choosing Rust would have been
detrimental. The team recognised that choosing Rust would come with many
drawbacks while offering only few benefits.

This left choosing Go as the logical conclusion. A large drawback that the team
identified with Go was the missing experience in the team. Two team members had
used Go before, but they last used it a few years back. However, since Go syntax
and the languages concepts hadn't changed much since then, it was deemed
possible to quickly get up to speed, much more quickly than Rust would have
allowed. The final decision fell on using Go, as it offered small binaries,
great memory efficiency, a solid ecosystem of libraries and build-tools and a
feature-rich, built-in library for creating REST-APIs. Go also removes a lot of
the pitfalls that Rust suffers from: it has a simple and approachable syntax and
a very low-friction, high-speed development experience. This was also the
deciding factor, since it was made clear to the team that getting an MVP up and
running as quickly as possible was imperative for the project.

\paragraph{PostgreSQL}
The plan for the MVP of Magpie set the simple goal of delivering useful data to
users. To achieve this, the data needs to be stored in a way in which it can be
efficiently accessed during operation. Since the goal of the project was to
provide a tool to professionals, data integrity at every level was an important
consideration. Additional requirements for the data storage solution were good
support for geospatial data, quick retrieval of a large number of points and
ease-of-use.

There is a plethora of database solutions available today. The team considered
the most common types: document databases like MongoDB and multi-model databases
like PostgreSQL (sometimes called RDBMS).

While document databases like MongoDB have their place in the current
development landscape, it soon became clear that SQL-based, multi-model RDBMSs
would be best suited for the job. They offer tried-and-tested performance and
reliability and they are well equipped to guarantee data integrity. But the
deciding reason was the pre-existing experience the lead developer for the
backend had with these types of databases.

After some deliberation, PostgreSQL was chosen as the database solution for this
project. It was combined with the PostGIS extension to add support for
geospatial data and queries. The decision was not cut and dried as most
established multi-model databases (like Oracle DB or MySQL) offer the
functionality that the requirements were asking for. However, the Kubernetes
cluster this project was going to be deployed on already had a fully configured
PostgreSQL server running on it. Making use of pre-existing infrastructure is
the obvious choice in an agile project that had the prime goal of hitting the
ground running.

\paragraph{sqlc}
\paragraph{golang-migrate}


\paragraph{bcrypt}

\subsubsection{Backend Development}
As discussed in \ref{systemarchitecture} \nameref{systemarchitecture}, the
backend is comprised of two standalone REST-API servers. Right after the
decision to split the backend was taken, a first implementation using two
separate codebases was created. This approach was functional, meaning it was
able to produce two distinct backends with different feature sets.

But it soon became obvious that this approach was not sustainable. While simply
splitting the backend into two codebases was a quick and easy solution, it would
almost certainly lead to significantly increased development times in the
future. The two backends have a fair amount of identical functionality and
differ just in the route handlers and the database queries. Leaving the
codebases separate would result in many changes being made twice -- once in the
private backend and once in the public backend.

After careful consideration and discussions with the team, the decision was made
to revert the change that split the backend. The desired result of two distinct
backends would have to be achieved in a different way.

To accomplish this, a feature of the Go programming language called
\textit{build-tags} was utilised. Usage examples of this feature showcase it by
creating multiple binaries that have different feature sets, for instance
multiple different payment tiers for a single software. This was a great
solution for this problem. It allowed for certain files to be excluded during
compilation based on if they were needed for private or public functionality.
While the development of such a program split by build-tags is more challenging
than developing a single binary, it is much more streamlined than keeping
functionality identical between two separate projects.

\subsubsection{Middlewares}
\paragraph{Authentication}
\paragraph{Authorisation}
\subsubsection{Data Validation}
\subsubsection{Error Handling}
\subsubsection{Testing}